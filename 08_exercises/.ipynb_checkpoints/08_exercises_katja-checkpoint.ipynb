{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises 8: Mutual Information #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy.stats as scist\n",
    "from scipy import optimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Density-Based Method ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file singleunit.py contains a function that simulates spike count output $\\vec{k}$ of two neurons for a\n",
    "stimulus with a single parameter $\\theta_n=(n/12) \\pi$, $n=0,...,11$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as scist\n",
    "\n",
    "def record(theta):\n",
    "\n",
    "    mu1=10.*(np.cos(theta-np.pi/8)+1)/2\n",
    "    \n",
    "    mu2=2.*(np.cos(theta-5*np.pi/8)+1)/2\n",
    "\n",
    "    k=np.zeros((2,len(theta)))\n",
    "    noise=np.random.rand(2,len(theta))\n",
    "    for n in range(len(theta)):\n",
    "        th=theta[n]\n",
    "        k[0,n]=scist.poisson.ppf(noise[0,n],mu1[n])\n",
    "        k[1,n]=scist.poisson.ppf(noise[1,n],mu2[n])\n",
    "\n",
    "\n",
    "    return k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) Sample $\\vec{k}$ from 100 repetitions of each of the 12 stimuli (uniform distribution of $\\theta$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thetas: [0.         0.26179939 0.52359878 0.78539816 1.04719755 1.30899694\n",
      " 1.57079633 1.83259571 2.0943951  2.35619449 2.61799388 2.87979327]\n"
     ]
    }
   ],
   "source": [
    "rep = 100\n",
    "theta = np.pi * np.arange(0, 12, 1) / 12\n",
    "\n",
    "print('Thetas:', theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = np.zeros((2, len(theta), rep))\n",
    "\n",
    "for i in range(rep):\n",
    "    k[:, :, i] = record(theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Find $\\vec{\\lambda}(\\theta)$ using a maximum (log)likelihood approach for the model distribution\n",
    "\n",
    "$$p(\\vec{k}|\\theta) = \\frac{[\\lambda_1(\\theta)]^{k_1} [\\lambda_2(\\theta)]^{k_2}}{k_1! k_2!} exp[−\\lambda_1(\\theta) − \\lambda_2(\\theta)]$$\n",
    "\n",
    "Use scipy.optimize.fmin to fit the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions for computing the negative log-likelihood and optimization\n",
    "def negative_loglikelihood(guess_lambda, *args):\n",
    "    # guess_lambda[0] = lambda_1, guess_lambda[0] = lambda_2\n",
    "    log_lik = np.sum((k_1 * np.log(guess_lambda[0]) - guess_lambda[0])) + np.sum((k_2 * np.log(guess_lambda[1]) - guess_lambda[1])) # log-likelihood from product of two Poissons\n",
    "    return -log_lik\n",
    "\n",
    "def minimize_likelihood(guess_lambda, k_1, k_2):\n",
    "    minimum = optimize.fmin(negative_loglikelihood, guess_lambda, args=(k_1,k_2))\n",
    "    return minimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: -1181.602342\n",
      "         Iterations: 53\n",
      "         Function evaluations: 102\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -1321.564034\n",
      "         Iterations: 59\n",
      "         Function evaluations: 112\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -1231.093885\n",
      "         Iterations: 58\n",
      "         Function evaluations: 110\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -1114.647721\n",
      "         Iterations: 70\n",
      "         Function evaluations: 129\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -911.951527\n",
      "         Iterations: 56\n",
      "         Function evaluations: 113\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -890.980141\n",
      "         Iterations: 57\n",
      "         Function evaluations: 114\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -584.447967\n",
      "         Iterations: 58\n",
      "         Function evaluations: 112\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -373.667349\n",
      "         Iterations: 63\n",
      "         Function evaluations: 119\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -121.809688\n",
      "         Iterations: 64\n",
      "         Function evaluations: 126\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 44.717207\n",
      "         Iterations: 54\n",
      "         Function evaluations: 104\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 148.890404\n",
      "         Iterations: 49\n",
      "         Function evaluations: 93\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 192.975854\n",
      "         Iterations: 46\n",
      "         Function evaluations: 89\n"
     ]
    }
   ],
   "source": [
    "lambdas = np.zeros((2, len(theta)))\n",
    "guess_lambda = np.random.rand(2)\n",
    "\n",
    "for i in range(len(theta)):\n",
    "    k_1 = k[0, i, :]\n",
    "    k_2 = k[1, i, :]\n",
    "    lambdas[:, i] = minimize_likelihood(guess_lambda, k_1, k_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda 1:\n",
      " [ 9.87995619 10.50004714 10.1099818   9.59995729  8.62003796  8.49002723\n",
      "  6.93001936  5.75001866  4.10998489  3.01999857  1.90003503  0.92997499] \n",
      "lambda 2:\n",
      " [0.66001084 0.77999619 1.26001327 1.27001517 1.63999784 1.76999209\n",
      " 1.96002026 2.06001403 2.18002424 1.75995724 1.67998993 1.38999322]\n"
     ]
    }
   ],
   "source": [
    "print('lambda 1:\\n', lambdas[0, :], '\\nlambda 2:\\n', lambdas[1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(lambdas[0, :], )\n",
    "plt.plot(lambdas[1, :])\n",
    "plt.xlabel('$\\\\theta$')\n",
    "_ = plt.ylabel('$\\lambda$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) Compute the entropy $H(K_i)$ of the marginal distribution of $p(k_i) = \\sum_j p(k_i|\\theta_j)p(\\theta_j)$ by numerical summation over all $N$ samples $k^{(n)}_i$.\n",
    "\n",
    "\n",
    "$$ H(K_i) = −N^{−1} \\sum_{n=1}^{N} ln [\\sum_j p(k_i^{(n)}|\\theta_j)p(\\theta_j)] $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(k, rep, lambdas, p_theta):\n",
    "    H = np.zeros(2)\n",
    "    for i in range(k.shape[0]):\n",
    "        curr_entropy = 0\n",
    "        for j in range(rep):\n",
    "            for l in range(len(p_theta)):\n",
    "                curr_margin = 0\n",
    "                for m in range(len(p_theta)):\n",
    "                    curr_margin += marginal(k[i, l, j], lambdas[i, m], p_theta[m])\n",
    "                curr_entropy += np.log(curr_margin)\n",
    "        H[i] = -curr_entropy / (rep*len(p_theta))\n",
    "    return H\n",
    "\n",
    "def marginal(k, lam, p_theta):\n",
    "    lik = (lam ** k) / (np.math.factorial(k)) * np.exp(-lam) * p_theta\n",
    "    return lik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy H(k1): 2.7687617706998795\n",
      "Entropy H(k2): 1.599863308112843\n"
     ]
    }
   ],
   "source": [
    "p_theta = np.full(len(theta), 1/12)\n",
    "\n",
    "H = entropy(k, rep, lambdas, p_theta)\n",
    "\n",
    "print('Entropy H(k1):', H[0])\n",
    "print('Entropy H(k2):', H[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neuron 1 has a larger variance (because it has a larger mean $\\lambda$ which for a Poisson neuron then also determines the variance) and therefore higher entropy (\"can produce richer code\"). \n",
    "\n",
    "Analytically, we saw this also in 1.(c) where we derived that the entropy scales with the logarithm of $\\sigma$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) Compute the mutual information $I(\\vec{K},\\theta) = H(\\vec{K}) − H(\\vec{K}|\\theta) = \\sum_i [H(K_i) − H(K_i|\\theta)]$ with the noise entropy \n",
    "\n",
    "$$H(K_i|\\theta) = N^{−1} \\sum_n [−k^{(n)}_i~ln(\\lambda_i(\\theta^{(n)})) + \\lambda_i(\\theta^{(n)}) + ln(k^{(n)}_i !)] $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutual_information(H, H_noise, k, lambdas):\n",
    "    mutual_information = np.sum(H - H_noise)\n",
    "    return mutual_information\n",
    "\n",
    "def noise_entropy(k, lambdas):\n",
    "    H_noise = np.zeros((k.shape[0]))\n",
    "    for i in range(k.shape[0]):\n",
    "        curr_h = 0\n",
    "        for j in range(k.shape[2]):\n",
    "            for l in range(k.shape[1]):\n",
    "                curr_h += -k[i, l, j] * np.log(lambdas[i, l]) + lambdas[i, l] + np.log(float(np.math.factorial(k[i, l, j])))\n",
    "        H_noise[i] = curr_h / (rep*len(p_theta))\n",
    "    return H_noise               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy H(k1): 2.7687617706998795\n",
      "Noise entropy H(k1|theta): 2.236609397340329\n",
      "Entropy H(k2): 1.599863308112843\n",
      "Noise entropy H(k2|theta): 1.5315070272768914\n",
      "Mutual information I: 0.600508654195502\n"
     ]
    }
   ],
   "source": [
    "H_noise = noise_entropy(k, lambdas)\n",
    "I = mutual_information(H, H_noise, k, lambdas)\n",
    "\n",
    "print('Entropy H(k1):', H[0])\n",
    "print('Noise entropy H(k1|theta):', H_noise[0])\n",
    "print('Entropy H(k2):', H[1])\n",
    "print('Noise entropy H(k2|theta):', H_noise[1])\n",
    "print('Mutual information I:', I)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For neuron 1, the difference between entropy and noise entropy is larger than for neuron 2. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(e) Compute the upper bound\n",
    "\n",
    "$$ I(\\vec{K},\\theta) = ln[1 + \\frac{var(\\theta)}{var(k_1)+var(k_2)}] / 2 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upper_bound(theta, k):\n",
    "    bound = np.log(1 + (np.var(theta) / (np.var(k[0, :, :]) + np.var(k[1, :, :]))) / 2)\n",
    "    return bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upper bound: 0.02112066453961229\n"
     ]
    }
   ],
   "source": [
    "bound = upper_bound(theta, k)\n",
    "\n",
    "print('Upper bound:', bound)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: there was a mistake in the upper bound formula."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(f) Repeat your computations for a prior distribution $p(\\theta)$ in which $\\theta_6$ occurs 10 times as often as all\n",
    "the other $\\theta$s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thetas: [0.         0.26179939 0.52359878 0.78539816 1.04719755 1.30899694\n",
      " 1.30899694 1.30899694 1.30899694 1.30899694 1.30899694 1.30899694\n",
      " 1.30899694 1.30899694 1.30899694 1.57079633 1.83259571 2.0943951\n",
      " 2.35619449 2.61799388 2.87979327]\n"
     ]
    }
   ],
   "source": [
    "# (a)\n",
    "\n",
    "rep = 100\n",
    "theta_raw = np.pi * np.arange(0, 12, 1) / 12\n",
    "theta = np.hstack((theta_raw[:5], np.full(10, theta_raw[5]), theta_raw[6:]))\n",
    "\n",
    "print('Thetas:', theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = np.zeros((2, len(theta), rep))\n",
    "\n",
    "for i in range(rep):\n",
    "    k[:, :, i] = record(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: -1116.689181\n",
      "         Iterations: 51\n",
      "         Function evaluations: 99\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -1283.800916\n",
      "         Iterations: 50\n",
      "         Function evaluations: 97\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -1312.439092\n",
      "         Iterations: 51\n",
      "         Function evaluations: 99\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -1168.765364\n",
      "         Iterations: 49\n",
      "         Function evaluations: 96\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -974.756459\n",
      "         Iterations: 44\n",
      "         Function evaluations: 87\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -803.833221\n",
      "         Iterations: 49\n",
      "         Function evaluations: 95\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -807.212469\n",
      "         Iterations: 48\n",
      "         Function evaluations: 95\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -776.202096\n",
      "         Iterations: 49\n",
      "         Function evaluations: 94\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -749.204755\n",
      "         Iterations: 48\n",
      "         Function evaluations: 93\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -874.878614\n",
      "         Iterations: 45\n",
      "         Function evaluations: 87\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -895.714732\n",
      "         Iterations: 45\n",
      "         Function evaluations: 90\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -817.181465\n",
      "         Iterations: 48\n",
      "         Function evaluations: 95\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -751.025856\n",
      "         Iterations: 45\n",
      "         Function evaluations: 89\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -868.097731\n",
      "         Iterations: 49\n",
      "         Function evaluations: 97\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -735.241015\n",
      "         Iterations: 42\n",
      "         Function evaluations: 83\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -505.613188\n",
      "         Iterations: 47\n",
      "         Function evaluations: 91\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -371.509831\n",
      "         Iterations: 54\n",
      "         Function evaluations: 104\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -191.033485\n",
      "         Iterations: 53\n",
      "         Function evaluations: 97\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 16.125998\n",
      "         Iterations: 45\n",
      "         Function evaluations: 86\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 150.652692\n",
      "         Iterations: 43\n",
      "         Function evaluations: 84\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 188.250748\n",
      "         Iterations: 39\n",
      "         Function evaluations: 72\n"
     ]
    }
   ],
   "source": [
    "# (b)\n",
    "\n",
    "lambdas = np.zeros((2, len(theta)))\n",
    "guess_lambda = np.random.rand(2)\n",
    "\n",
    "for i in range(len(theta)):\n",
    "    k_1 = k[0, i, :]\n",
    "    k_2 = k[1, i, :]\n",
    "    lambdas[:, i] = minimize_likelihood(guess_lambda, k_1, k_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda 1:\n",
      " [ 9.59999183 10.35000017 10.46001861  9.83996032  8.93997329  8.04003502\n",
      "  8.04997335  7.91000906  7.79995779  8.43999781  8.52000891  8.10998622\n",
      "  7.80001647  8.38007394  7.77999356  6.57004183  5.7999792   4.55004217\n",
      "  3.23996229  2.01000154  0.81999137] \n",
      "lambda 2:\n",
      " [0.69000672 1.02000859 1.24999706 1.24999314 1.49000216 1.8999976\n",
      " 1.9199846  1.89002269 1.81997972 1.66998385 1.74001981 1.88000454\n",
      " 1.84999621 1.77999185 1.63998556 1.79999751 1.89998339 2.24000084\n",
      " 1.82001126 1.480021   1.4799517 ]\n"
     ]
    }
   ],
   "source": [
    "print('lambda 1:\\n', lambdas[0, :], '\\nlambda 2:\\n', lambdas[1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy H(k1): 2.6984074109614937\n",
      "Entropy H(k2): 1.6170000687663078\n"
     ]
    }
   ],
   "source": [
    "# (c)\n",
    "\n",
    "p_theta = np.full(len(theta), 1/21)\n",
    "\n",
    "H = entropy(k, rep, lambdas, p_theta)\n",
    "\n",
    "print('Entropy H(k1):', H[0])\n",
    "print('Entropy H(k2):', H[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy H(k1): 2.6984074109614937\n",
      "Noise entropy H(k1|theta): 2.3205135216422033\n",
      "Entropy H(k2): 1.6170000687663078\n",
      "Noise entropy H(k2|theta): 1.577796979418256\n",
      "Mutual information I: 0.4170969786673422\n"
     ]
    }
   ],
   "source": [
    "# (d)\n",
    "\n",
    "H_noise = noise_entropy(k, lambdas)\n",
    "I = mutual_information(H, H_noise, k, lambdas)\n",
    "\n",
    "print('Entropy H(k1):', H[0])\n",
    "print('Noise entropy H(k1|theta):', H_noise[0])\n",
    "print('Entropy H(k2):', H[1])\n",
    "print('Noise entropy H(k2|theta):', H_noise[1])\n",
    "print('Mutual information I:', I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upper bound: 0.015147270582199352\n"
     ]
    }
   ],
   "source": [
    "# (e)\n",
    "\n",
    "bound = upper_bound(theta, k)\n",
    "\n",
    "print('Upper bound:', bound)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment on 1.(f):\n",
    "\n",
    "For both neurons, the difference between the entropy and noise entropy decreases.\n",
    "\n",
    "THerefore, the mutual information becomes smaller because with the peaked stimulus distributions (distribution of thetas), the output is more certain (less surprising / smaller variability), which leads to a smaller variability in the output and therefore variability that is still in the output is due to contribution of the noise."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
